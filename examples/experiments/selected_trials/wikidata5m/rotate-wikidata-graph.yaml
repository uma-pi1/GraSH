dataset:
  name: wikidata5m
entity_ranking:
  chunk_size: 25000
eval:
  batch_size: 256
import:
- rotate
job:
  type: train
lookup_embedder:
  class_name: LookupEmbedder
  dim: 128
  dropout: 0.0
  initialize: uniform_
  initialize_args:
    normal_:
      mean: 0.0
      std: 2.437881721852854e-05
    uniform_:
      a: -0.4908908530858923
    xavier_normal_:
      gain: 1.0
    xavier_uniform_:
      gain: 1.0
  normalize:
    p: -1.0
  regularize: ''
  regularize_args:
    p: 2
    weighted: true
  sparse: true
model: rotate
negative_sampling:
  class_name: TrainingJobNegativeSampling
  implementation: batch
  num_samples:
    o: 695
    p: 0
    s: 457
  sampling_type: uniform
  shared: true
  shared_type: default
  with_replacement: false
rotate:
  class_name: RotatE
  entity_embedder:
    dropout: 0.21786015136038406
    regularize_weight: 9.958739678235862e-08
    type: lookup_embedder
  l_norm: 1.0
  normalize_phases: true
  relation_embedder:
    dim: -1
    dropout: -0.14434832965649225
    initialize: uniform_
    initialize_args:
      uniform_:
        a: -3.14159265359
        b: 3.14159265359
    regularize_weight: 7.635983581700862e-19
    type: lookup_embedder
train:
  auto_correct: true
  batch_size: 1024
  loss: kl
  loss_arg: 1.0
  max_epochs: 64
  num_workers: 0
  optimizer:
    default:
      args:
        lr: 0.07506700382872376
      type: Adagrad
  type: negative_sampling
valid:
  early_stopping:
    patience: 0
    threshold:
      epochs: 0
      metric_value: 0.0
  every: 4
